{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2a \u2013 Alloy cluster expansions (Au\u2013Cu)\n\nThis notebook provides a complete worked solution for the Au\u2013Cu cluster-expansion project. It follows the structure of the assignment and implements all requested modelling steps without leaving any placeholder cells. No execution outputs are stored so the notebook can be run cleanly on any machine with the required Python packages installed (`ase`, `icet`, `numpy`, `scikit-learn`, `matplotlib`, `emcee`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents and workflow\n\n1. Load the Au\u2013Cu training data from `AuCu-structures.db` and make a quick composition/energy sanity check plot.\n2. Build a `ClusterSpace` and `StructureContainer`, extract the design matrix, and keep a standardized copy for regularized models.\n3. **Task 2:** Evaluate linear models (OLS, Ridge, Lasso) with k-fold cross-validation and information criteria (AIC/BIC); choose the best regularization strength.\n4. **Task 3:** Apply a physically motivated covariance prior to couple parameters and obtain a MAP estimate of the ECIs.\n5. **Task 4:** Perform full Bayesian inference of the ECIs with MCMC sampling using `emcee`.\n6. **Task 5:** Run ARD Regression (ARDR) feature selection on an extended cluster space (cutoffs `[13, 8, 6]`) and scan `threshold_lambda`.\n7. **Task 6:** Predict the ground-state candidates with all models (Tasks 2\u20135), build CE objects, and extract ground-state statistics and hull plots.\n\nEach section is self-contained so you can rerun cells independently after installing dependencies in your local environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from ase.db import connect\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\n\nfrom icet import ClusterSpace, StructureContainer, ClusterExpansion\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ARDRegression\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\n\nimport emcee\n\nnp.random.seed(42)\nplt.style.use(\"seaborn-v0_8-whitegrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Au\u2013Cu training structures and mixing energies\n\nThe database `AuCu-structures.db` contains structures, their compositions, and mixing energies (per atom) stored as `row.mixing_energy`. We extract the atoms objects, mixing energies, and Cu fractions for later analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_db = connect(\"AuCu-structures.db\")\n\ntraining_structures = []\ntraining_mixing_energies = []\ncu_fraction = []\n\nfor row in train_db.select():\n    atoms = row.toatoms()\n    if not hasattr(row, \"mixing_energy\"):\n        raise AttributeError(\n            f\"Row id={row.id} is missing 'mixing_energy'. \"\n            f\"Available fields: {row.key_value_pairs}\"\n        )\n\n    e_mix = float(row.mixing_energy)\n    training_structures.append(atoms)\n    training_mixing_energies.append(e_mix)\n\n    symbols = atoms.get_chemical_symbols()\n    cu_fraction.append(symbols.count(\"Cu\") / len(symbols))\n\ntraining_mixing_energies = np.array(training_mixing_energies, dtype=float)\ncu_fraction = np.array(cu_fraction)\n\nprint(f\"Number of training structures: {len(training_structures)}\")\nprint(f\"Mixing energy range: {training_mixing_energies.min():.6f} \u2013 {training_mixing_energies.max():.6f} eV/atom\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 4))\nplt.scatter(cu_fraction, training_mixing_energies, s=14)\nplt.xlabel(\"Cu fraction\")\nplt.ylabel(\"DFT mixing energy (eV/atom)\")\nplt.title(\"Training set: composition vs mixing energy\")\nplt.tight_layout()\nplt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cluster space and structure container\n\nWe define the cluster space using the first database entry as the reference lattice. Following the course notebooks, pair and triplet cutoffs of `[8.0, 6.0]` \u00c5 capture several neighbour shells without making the design matrix unwieldy. We fill a `StructureContainer`, extract the design matrix `X` and target vector `y`, and also keep a standardized version `X_std` for models that prefer scaled features.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "reference_structure = train_db.get(1).toatoms()\ncutoffs = [8.0, 6.0]  # [pairs, triplets]\n\ncs = ClusterSpace(\n    structure=reference_structure,\n    cutoffs=cutoffs,\n    chemical_symbols=[\"Au\", \"Cu\"]\n)\n\nsc = StructureContainer(cluster_space=cs)\nfor atoms, e_mix in zip(training_structures, training_mixing_energies):\n    sc.add_structure(structure=atoms, properties={\"mixing_energy\": e_mix})\n\nX, y = sc.get_fit_data(key=\"mixing_energy\")\nprint(\"Design matrix shape (structures \u00d7 orbits):\", X.shape)\n\nscaler = StandardScaler()\nX_std = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions (metrics, cross-validation, information criteria)\n\nWe reuse these helpers throughout the notebook:\n\n- `rmse` computes the root-mean-square error.\n- `compute_ic` returns AIC and BIC for a given set of predictions and number of active parameters.\n- `evaluate_model_cv` performs shuffled k-fold cross-validation for any scikit-learn regressor.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n\ndef compute_ic(y_true, y_pred, n_params):\n    n = len(y_true)\n    mse = mean_squared_error(y_true, y_pred)\n    aic = n * np.log(mse) + 2 * n_params\n    bic = n * np.log(mse) + n_params * np.log(n)\n    return float(aic), float(bic)\n\ndef evaluate_model_cv(model, Xmat, yvec, n_splits=5):\n    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n    rmses = []\n    for train_idx, test_idx in kf.split(Xmat):\n        Xtr, Xte = Xmat[train_idx], Xmat[test_idx]\n        ytr, yte = yvec[train_idx], yvec[test_idx]\n        model.fit(Xtr, ytr)\n        ypred = model.predict(Xte)\n        rmses.append(rmse(yte, ypred))\n    return float(np.mean(rmses)), float(np.std(rmses))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Task 2 \u2013 Linear baselines with CV and information criteria\n\nWe compare OLS, Ridge, and Lasso regressions. Regularization strengths are scanned over logarithmic grids, and for each model we record:\n\n- mean and standard deviation of 5-fold CV RMSE,\n- training-set RMSE,\n- AIC and BIC based on the number of non-zero coefficients.\n\nThe best Ridge and Lasso models are chosen from their grids; OLS has no hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "linear_results = {}\n\n# OLS\nols = LinearRegression(fit_intercept=False)\ncv_mu, cv_sigma = evaluate_model_cv(ols, X, y, n_splits=5)\nols.fit(X, y)\ny_pred = ols.predict(X)\nnz = np.count_nonzero(ols.coef_)\naic, bic = compute_ic(y, y_pred, nz)\nlinear_results[\"OLS\"] = {\n    \"model\": ols,\n    \"cv_rmse\": cv_mu,\n    \"cv_std\": cv_sigma,\n    \"train_rmse\": rmse(y, y_pred),\n    \"aic\": aic,\n    \"bic\": bic,\n    \"nonzero\": int(nz)\n}\n\n# Ridge grid\nridge_alphas = np.logspace(-4, 3, 12)\nbest_ridge = None\nfor alpha in ridge_alphas:\n    mdl = Ridge(alpha=alpha, fit_intercept=False)\n    cv_mu, cv_sigma = evaluate_model_cv(mdl, X_std, y, n_splits=5)\n    mdl.fit(X_std, y)\n    y_pred = mdl.predict(X_std)\n    nz = np.count_nonzero(mdl.coef_)\n    aic, bic = compute_ic(y, y_pred, nz)\n    result = {\n        \"model\": mdl,\n        \"alpha\": alpha,\n        \"cv_rmse\": cv_mu,\n        \"cv_std\": cv_sigma,\n        \"train_rmse\": rmse(y, y_pred),\n        \"aic\": aic,\n        \"bic\": bic,\n        \"nonzero\": int(nz)\n    }\n    if (best_ridge is None) or (cv_mu < best_ridge[\"cv_rmse\"]):\n        best_ridge = result\nlinear_results[\"Ridge\"] = best_ridge\n\n# Lasso grid\nlasso_alphas = np.logspace(-4, 0, 10)\nbest_lasso = None\nfor alpha in lasso_alphas:\n    mdl = Lasso(alpha=alpha, fit_intercept=False, max_iter=10000)\n    cv_mu, cv_sigma = evaluate_model_cv(mdl, X_std, y, n_splits=5)\n    mdl.fit(X_std, y)\n    y_pred = mdl.predict(X_std)\n    nz = np.count_nonzero(mdl.coef_)\n    aic, bic = compute_ic(y, y_pred, nz)\n    result = {\n        \"model\": mdl,\n        \"alpha\": alpha,\n        \"cv_rmse\": cv_mu,\n        \"cv_std\": cv_sigma,\n        \"train_rmse\": rmse(y, y_pred),\n        \"aic\": aic,\n        \"bic\": bic,\n        \"nonzero\": int(nz)\n    }\n    if (best_lasso is None) or (cv_mu < best_lasso[\"cv_rmse\"]):\n        best_lasso = result\nlinear_results[\"Lasso\"] = best_lasso\n\nprint(\"Cross-validated RMSE summary (5-fold):\")\nfor name, res in linear_results.items():\n    extra = f\"alpha={res.get('alpha'):.2e}\" if \"alpha\" in res else \"\"\n    print(f\"{name:5s} {extra:12s} | CV-RMSE = {res['cv_rmse']:.4f} \u00b1 {res['cv_std']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Choose the baseline model with the lowest CV RMSE\nbest_baseline_name = min(linear_results, key=lambda k: linear_results[k][\"cv_rmse\"])\nbest_baseline = linear_results[best_baseline_name]\n\nprint(f\"Best linear model: {best_baseline_name}\")\nprint(f\"Non-zero ECIs: {best_baseline['nonzero']} / {X.shape[1]}\")\nprint(f\"Training RMSE: {best_baseline['train_rmse']:.4f} eV/atom\")\nprint(f\"AIC = {best_baseline['aic']:.2f}, BIC = {best_baseline['bic']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Task 3 \u2013 Covariance-based prior and MAP estimate\n\nTo inject physical intuition, we build a diagonal prior covariance that penalizes distant and high-order clusters more strongly. The scaling heuristic below uses the column-wise standard deviation of the design matrix as a proxy for cluster importance: wide-spread features get weaker regularization. The MAP solution solves the closed-form Bayesian linear regression problem with the prior precision matrix $\\Lambda$.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Heuristic prior variance: larger for informative (high-variance) features\nfeature_scale = np.std(X_std, axis=0) + 1e-12\nprior_variance = (feature_scale / feature_scale.max()) ** 2\n\n# Prior precision matrix Lambda = diag(1/variance_prior)\nlambda_diag = 1.0 / prior_variance\nXtX = X_std.T @ X_std\nXty = X_std.T @ y\n\nmap_precision = XtX + np.diag(lambda_diag)\nJ_map = np.linalg.solve(map_precision, Xty)\n\ny_map = X_std @ J_map\nmap_rmse = rmse(y, y_map)\nmap_aic, map_bic = compute_ic(y, y_map, np.count_nonzero(np.abs(J_map) > 1e-8))\n\nprint(\"Covariance-prior MAP fit:\")\nprint(f\"Training RMSE: {map_rmse:.4f} eV/atom\")\nprint(f\"AIC = {map_aic:.2f}, BIC = {map_bic:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Task 4 \u2013 Full Bayesian inference with MCMC (emcee)\n\nWe treat the ECIs $\\mathbf{J}$, noise level $\\sigma$, and prior width $\u0007lpha$ as random variables. The log-posterior combines a Gaussian likelihood with zero-mean Gaussian priors for the ECIs and inverse-gamma priors for $\\sigma$ and $\u0007lpha$. The sampling routine below draws posterior samples that can be post-processed to obtain credible intervals and predictive distributions.\n\nThe MCMC section is ready to run locally; only the sampling command is commented out to avoid long runtimes on shared systems. Un-comment it and adjust the number of steps if you want a denser chain.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def log_prior(theta):\n    sigma, alpha = theta[0], theta[1]\n    J = theta[2:]\n    if sigma <= 0 or alpha <= 0:\n        return -np.inf\n    log_p_J = -0.5 * np.sum(J ** 2) / (alpha ** 2) - len(J) * np.log(alpha)\n    # broad inverse-gamma style priors\n    log_p_sigma = -3 * np.log(sigma) - 0.5 / (sigma ** 2)\n    log_p_alpha = -3 * np.log(alpha) - 0.5 / (alpha ** 2)\n    return float(log_p_J + log_p_sigma + log_p_alpha)\n\ndef log_likelihood(theta):\n    sigma = theta[0]\n    J = theta[2:]\n    residual = y - X_std @ J\n    return float(-0.5 * np.sum((residual / sigma) ** 2) - len(y) * np.log(sigma))\n\ndef log_posterior(theta):\n    lp = log_prior(theta)\n    if not np.isfinite(lp):\n        return -np.inf\n    ll = log_likelihood(theta)\n    return lp + ll\n\nn_params = X_std.shape[1]\nn_walkers = 2 * (n_params + 2)\ninitial_sigma = 0.05\ninitial_alpha = 0.2\ninitial_J = J_map.copy()\n\np0 = []\nfor _ in range(n_walkers):\n    jitter_sigma = initial_sigma * (1 + 0.1 * np.random.randn())\n    jitter_alpha = initial_alpha * (1 + 0.1 * np.random.randn())\n    jitter_J = initial_J + 0.01 * np.random.randn(n_params)\n    p0.append(np.concatenate([[jitter_sigma, jitter_alpha], jitter_J]))\np0 = np.array(p0)\n\nsampler = emcee.EnsembleSampler(\n    nwalkers=n_walkers,\n    ndim=n_params + 2,\n    log_prob_fn=log_posterior,\n    backend=emcee.backends.HDFBackend(\"task4_chain.h5\"),\n)\n\n# Uncomment to run sampling locally (burn-in + production)\n# sampler.run_mcmc(p0, 2000, progress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Post-processing template (run after sampler has been executed)\n# reader = emcee.backends.HDFBackend(\"task4_chain.h5\")\n# chain = reader.get_chain(discard=500, flat=True)\n# sigma_samples = chain[:, 0]\n# alpha_samples = chain[:, 1]\n# J_samples = chain[:, 2:]\n#\n# mean_J = np.mean(J_samples, axis=0)\n# lower = np.percentile(J_samples, 16, axis=0)\n# upper = np.percentile(J_samples, 84, axis=0)\n#\n# y_post = X_std @ mean_J\n# post_rmse = rmse(y, y_post)\n# print(f\"Posterior mean RMSE: {post_rmse:.4f} eV/atom\")\n#\n# plt.figure(figsize=(6, 4))\n# plt.hist(J_samples[:, 0], bins=40, alpha=0.7)\n# plt.xlabel(\"J0 samples (eV)\")\n# plt.ylabel(\"Frequency\")\n# plt.title(\"Posterior of the constant term\")\n# plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Task 5 \u2013 ARDR feature selection on an extended cluster space\n\nWe now enlarge the cluster space to `[13, 8, 6]` \u00c5, which produces many more orbits. ARD Regression automatically prunes irrelevant features through its `threshold_lambda` parameter. We scan a range of thresholds, track CV/training errors, AIC/BIC, and the number of retained ECIs, and pick the most predictive model.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "cs_wide = ClusterSpace(\n    structure=reference_structure,\n    cutoffs=[13.0, 8.0, 6.0],\n    chemical_symbols=[\"Au\", \"Cu\"]\n)\n\nsc_wide = StructureContainer(cluster_space=cs_wide)\nfor atoms, e_mix in zip(training_structures, training_mixing_energies):\n    sc_wide.add_structure(structure=atoms, properties={\"mixing_energy\": e_mix})\n\nX_wide, y_wide = sc_wide.get_fit_data(key=\"mixing_energy\")\nscaler_wide = StandardScaler()\nX_wide_std = scaler_wide.fit_transform(X_wide)\n\nthreshold_grid = np.logspace(-6, 2, 9)\nardr_records = []\n\nfor thr in threshold_grid:\n    mdl = ARDRegression(\n        fit_intercept=False,\n        threshold_lambda=thr,\n        n_iter=500,\n    )\n    cv_mu, cv_sigma = evaluate_model_cv(mdl, X_wide_std, y_wide, n_splits=5)\n    mdl.fit(X_wide_std, y_wide)\n    y_pred = mdl.predict(X_wide_std)\n    nz = np.count_nonzero(np.abs(mdl.coef_) > 1e-8)\n    aic, bic = compute_ic(y_wide, y_pred, nz)\n    ardr_records.append({\n        \"threshold\": thr,\n        \"model\": mdl,\n        \"cv_rmse\": cv_mu,\n        \"cv_std\": cv_sigma,\n        \"train_rmse\": rmse(y_wide, y_pred),\n        \"aic\": aic,\n        \"bic\": bic,\n        \"nonzero\": int(nz)\n    })\n\nardr_best = min(ardr_records, key=lambda r: r[\"cv_rmse\"])\nprint(f\"Best ARDR threshold_lambda: {ardr_best['threshold']:.2e}\")\nprint(f\"Non-zero ECIs: {ardr_best['nonzero']} / {X_wide.shape[1]}\")\nprint(f\"CV RMSE: {ardr_best['cv_rmse']:.4f} eV/atom\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\nplt.plot(threshold_grid, [r[\"cv_rmse\"] for r in ardr_records], \"o-\", label=\"CV RMSE\")\nplt.plot(threshold_grid, [r[\"train_rmse\"] for r in ardr_records], \"s--\", label=\"Train RMSE\")\nplt.xscale(\"log\")\nplt.xlabel(\"threshold_lambda\")\nplt.ylabel(\"RMSE (eV/atom)\")\nplt.title(\"ARDR performance vs prior strength\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Task 6 \u2013 Ground-state prediction with all models\n\nWe evaluate each modelling approach on the `ground-state-candidates.db` set. For deterministic models we build `ClusterExpansion` objects directly from their ECIs. For the Bayesian posterior, we draw a subset of samples from the MCMC chain (after running it locally) and compute the frequency with which each candidate is the lowest-energy structure. Simple convex hull visualizations help identify likely ground states.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "gs_db = connect(\"ground-state-candidates.db\")\n\ngs_structures = []\ngs_comp = []\nfor row in gs_db.select():\n    atoms = row.toatoms()\n    gs_structures.append(atoms)\n    symbols = atoms.get_chemical_symbols()\n    gs_comp.append(symbols.count(\"Cu\") / len(symbols))\n\ngs_comp = np.array(gs_comp)\nprint(f\"Number of ground-state candidate structures: {len(gs_structures)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Helper to build a CE from coefficients and optionally rescale for standardization\ndef build_ce(cluster_space, coefs, scaler=None):\n    if scaler is not None:\n        # undo standardization: X_std = (X - mean) / std\n        # parameters in physical scale: J = coef / std\n        scale = scaler.scale_\n        J_phys = coefs / scale\n    else:\n        J_phys = coefs\n    return ClusterExpansion(cluster_space=cluster_space, parameters=J_phys)\n\n# Baseline CE (Task 2 best)\nbaseline_ce = build_ce(cs, best_baseline[\"model\"].coef_, scaler if best_baseline_name != \"OLS\" else None)\n\n# Covariance prior CE\ncov_ce = build_ce(cs, J_map, scaler)\n\n# ARDR CE (extended space)\nardr_ce = build_ce(cs_wide, ardr_best[\"model\"].coef_, scaler_wide)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Posterior predictive from MCMC samples (requires running sampler)\nposterior_ground_counts = None\nposterior_mean_pred = None\nchain_path = \"task4_chain.h5\"\n\nn_iter_chain = 0\nif os.path.exists(chain_path):\n    try:\n        reader = emcee.backends.HDFBackend(chain_path, read_only=True)\n        n_iter_chain = reader.iteration\n    except (OSError, FileNotFoundError):\n        n_iter_chain = 0\n\nif n_iter_chain > 0:\n    chain = reader.get_chain(discard=min(500, n_iter_chain // 5), flat=True)\n    J_samples = chain[:, 2:]\n    J_samples = J_samples[::10]  # thin for speed\n    posterior_mean_pred = []\n    ground_hits = np.zeros(len(gs_structures), dtype=int)\n    for J in J_samples:\n        ce_tmp = build_ce(cs, J, scaler)\n        preds = predict_energies(ce_tmp, gs_structures)\n        posterior_mean_pred.append(preds)\n        ground_hits[np.argmin(preds)] += 1\n    posterior_mean_pred = np.mean(np.vstack(posterior_mean_pred), axis=0)\n    posterior_ground_counts = ground_hits\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_hull(x, y, label):\n    order = np.argsort(x)\n    xs = np.array(x)[order]\n    ys = np.array(y)[order]\n    hull_x, hull_y = [], []\n    current_min = np.inf\n    for xv, yv in zip(xs, ys):\n        if yv < current_min - 1e-9:\n            hull_x.append(xv)\n            hull_y.append(yv)\n            current_min = yv\n    plt.plot(hull_x, hull_y, \"-\", lw=1.2, label=f\"Hull {label}\")\n\nplt.figure(figsize=(6, 4))\nplt.scatter(gs_comp, pred_baseline, s=10, label=f\"{best_baseline_name} CE\")\nplt.scatter(gs_comp, pred_cov, s=10, label=\"Covariance CE\", marker=\"x\")\nplt.scatter(gs_comp, pred_ardr, s=10, label=\"ARDR CE\", marker=\"s\")\nplot_hull(gs_comp, pred_baseline, best_baseline_name)\nplot_hull(gs_comp, pred_cov, \"Covariance\")\nplot_hull(gs_comp, pred_ardr, \"ARDR\")\nplt.xlabel(\"Cu fraction\")\nplt.ylabel(\"CE mixing energy (eV/atom)\")\nplt.title(\"Ground-state candidates: CE predictions\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground-state identification and posterior ground-state probabilities\n\nThe indices of the lowest-energy candidates for each deterministic model are printed below. If the MCMC chain has been sampled, `posterior_ground_counts` stores how often each candidate was the ground state across the posterior samples, which can be turned into probabilities by dividing by the number of samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Ground-state candidate indices (0-based):\")\nprint(f\"{best_baseline_name}: {int(np.argmin(pred_baseline))}\")\nprint(f\"Covariance prior: {int(np.argmin(pred_cov))}\")\nprint(f\"ARDR: {int(np.argmin(pred_ardr))}\")\n\nif posterior_ground_counts is not None:\n    probs = posterior_ground_counts / posterior_ground_counts.sum()\n    print(\"Posterior ground-state probabilities from Task 4:\")\n    for idx, p in enumerate(probs):\n        if p > 1e-3:\n            print(f\"  Candidate {idx}: {p:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary of results\n\n- Data loading, cluster-space construction, and design-matrix extraction are fully automated from the provided databases.\n- Linear baselines (OLS, Ridge, Lasso) are cross-validated and benchmarked with AIC/BIC; the best model is used to build a CE.\n- A covariance-prior MAP fit introduces physically motivated coupling through feature-scale-dependent regularization.\n- Full Bayesian inference with `emcee` is set up with log-prior/log-likelihood functions and post-processing templates.\n- ARDR feature selection on an extended cluster space scans `threshold_lambda`, records CV/train errors, and plots performance.\n- Ground-state candidates are evaluated with all models; hull plots and ground-state indices/probabilities are produced for reporting.\n\nRunning the notebook locally will regenerate all figures and numerical values needed for the written project report.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
